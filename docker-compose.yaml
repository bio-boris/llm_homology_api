  version: '3.8'  # Make sure you're using a version that supports device_requests
  services:
    llm_homology_api:
      build:
        context: .
        args:
          VCS_REF: ${VCS_REF}
          VERSION: ${VERSION}
        dockerfile: Dockerfile
      ports:
        - "5001:5000"
      env_file:
        - .docker_compose_env
      environment:
        - PYTHONPATH=.:llm_homology_api:llm_homology_api/src
      entrypoint: poetry run uvicorn --host 0.0.0.0 --port 5000 --factory llm_homology_api.src.factory:create_app --reload

      volumes:
        - /scratch/sprot/sprot_esm_650m_faiss:/models/sprot_esm_650m_faiss
        - /scratch/sprot/sprot_esm_650m_faiss.index:/models/sprot_esm_650m_faiss.index
      develop:
        watch:
          # sync static content
          - path: ./llm_homology_api
            action: sync
            target: /app/llm_homology_api/
            ignore:
              - node_modules/

      deploy:
        resources:
          reservations:
            devices:
              - driver: nvidia
                count: all
                capabilities: [gpu]